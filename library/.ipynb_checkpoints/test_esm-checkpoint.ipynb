{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import hmmscan_utils as hu\n",
    "# import ml_utils as ml\n",
    "# import pickle\n",
    "# from pathlib import Path\n",
    "# from Bio import SeqIO\n",
    "# from esm import FastaBatchedDataset, pretrained\n",
    "# from torch import nn\n",
    "# from tqdm import tqdm\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "sys.path.insert(0, '../library')\n",
    "import hmmscan_utils as hu\n",
    "import ml_utils as mu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load ESM2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Initialize a random tensor of size 19633\n",
    "x = torch.randn(19633)*1000\n",
    "\n",
    "# Initialize a target tensor of the same size\n",
    "y = torch.zeros(19633)\n",
    "y[1]=1\n",
    "\n",
    "# Compute the L1 loss\n",
    "loss = F.l1_loss(x, y)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(Path('../data_esm_decoder') / 'maps.pkl', 'rb') as f:\n",
    "    maps = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hmmscan_utils as hu\n",
    "import ml_utils as mu\n",
    "import classifiers as c\n",
    "import torch\n",
    "from esm import pretrained\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "hmm_data = hu.parse_hmmscan_results(\"../data/split_1_train_ids_full.fasta_scan.txt\")\n",
    "\n",
    "# Load esm2\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_name = 'esm2_t33_650M_UR50D'\n",
    "model, alphabet = pretrained.load_model_and_alphabet(model_name)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "last_layer = model.num_layers\n",
    "embed_dim = model.embed_dim\n",
    "\n",
    "# Load model\n",
    "classifier = c.TryLSTM(embed_dim, 657).to(device)\n",
    "# classifier = mu.ContextWeightedSum(embed_dim, 657).to(device)\n",
    "state_dict = torch.load(\"../data/results/try_lstm_run1/epoch_4.pth\")\n",
    "# state_dict = torch.load(\"../data/results/context_weighted_run1/epoch_2.pth\")\n",
    "\n",
    "classifier.load_state_dict(state_dict)\n",
    "\n",
    "# Load maps and generate idx_to_clan map\n",
    "with open(Path('../data_esm_decoder') / 'maps.pkl', 'rb') as f:\n",
    "        maps = pickle.load(f)\n",
    "idx_to_clan = {v: k for k, v in maps[\"clan_idx\"].items()}\n",
    "idx_to_fam = {v: k for k,v in maps[\"fam_idx\"].items()}\n",
    "\n",
    "# Run esm2\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "# Prepare data (first 2 sequences from ESMStructuralSplitDataset superfamily / 4)\n",
    "data = [\n",
    "    (\"Q59325\",\"MKFRRSICTAVLLAVLLTLLVPTSVFALEDNSSTLPPYKNDLLYERTFDEGLCYPWHTCEDSGGKCSFDVVDVPGQPGNKAFAVTVLDKGQNRWSVQMRHRGLTLEQGHTYRVRLKIWADASCKVYIKIGQMGEPYAEYWNNKWSPYTLTAGKVLEIDETFVMDKPTDDTCEFTFHLGGELAATPPYTVYLDDVSLYDPEYTKPVEYILPQPDVRVNQVGYLPEGKKVATVVCNSTQPVKWQLKNAAGVVVLEGYTEPKGLDKDSQDYVHWLDFSDFATEGIGYYFELPTVNSPTNYSHPFDIRKDIYTQMKYDALAFFYHKRSGIPIEMPYAGGEQWTRPAGHIGIEPNKGDTNVPTWPQDDEYAGIPQKNYTKDVTGGWYDAGDHGKYVVNGGIAVWTLMNMYERAKIRGLDNWGPYRDGGMNIPEQNNGYPDILDEARWEIEFFKKMQVTEKEDPSIAGMVHHKIHDFRWTALGMLPHEDPQPRYLRPVSTAATLNFAATLAQSARLWKDYDPTFAADCLEKAEIAWQAALKHPDIYAEYTPGSGGPGGGPYNDDYVGDEFYWAACELYVTTGKDEYKNYLMNSPHYLEMPAKMGENGGANGEDNGLWGCFTWGTTQGLGTITLALVENGLPATDIQKARNNIAKAADRWLENIEEQGYRLPIKQAEDERGGYPWGSNSFILNQMIVMGYAYDFTGDSKYLDGMFDGISYLLGRNAMDQSYVTGYGERPLQNPHDRFWTPQTSKRFPAPPPGIISGGPNSRFEDPTINAAVKKDTPPQKCFIDHTDSWSTNEITVNWNAPFAWVTAYLDEQYTDSETDKVTIDSPVAGERFEAGKDINISATVKSKTPVSKVEFYNGDTLISSDTTAPYTAKITGAAVGAYNLKAVAVLSDGRRIESPVTPVLVKVIVKPTVKLTAPKSNVVAYGNEFLKITATASDSDGKISRVDFLVDGEVIGSDREAPYEYEWKAVEGNHEISVIAYDDDDAASTPDSVKIFVKQARDVKVQYLCENTQTSTQEIKGKFNIVNTGNRDYSLKDIVLRYYFTKEHNSQLQFICYYTPIGSGNLIPSFGGSGDEHYLQLEFKDVKLPAGGQTGEIQFVIRYADNSFHDQSNDYSFDPTIKAFQDYGKVTLYKNGELVWGTPPGGTEPEEPEEPEEPEEPAIVYGDCNDDGKVNSTDVAVMKRYLKKENVNINLDNADVNADGKVNSTDFSILKRYVMKNIEELPYR\")\n",
    "    ]\n",
    "# data = [(\"rdrp\",\"MDVDTAFLNSTMDEPIYVKQPPGFVNERNPDYVWELYGGMYGLKQAPLLWNEHINNTLKKIGFCRHEGEHGLYFRSTSDGPIYIAVYVDDLLVAAPSPKIYDRVKQELTKLYSMKDLGKVDKFLGLNIHQSSNGDITLSLQDYIAKAASESEINTFKLTQTPLCNSKPLFETTSPHLKDITPYQSIVGQLLFCANTGRPDISYPVSLLSRFLREPRAIHLESARRVLRYLYTTRSMCLKYRSGSQLALTVYCDASHGAIHDLPHSTGGYVTLLAGAPVTWSSKKLKGVIPVPSTEAEYITASETVMEI\")]\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "\n",
    "\n",
    "results = model(batch_tokens.to(device), repr_layers=[33], return_contacts=True)\n",
    "token_representations = results[\"representations\"][33]\n",
    "\n",
    "# Get preds\n",
    "emb = token_representations[0,1:-1,:]\n",
    "clan_preds = classifier(emb)\n",
    "clan_preds = torch.nn.functional.softmax(clan_preds,dim=1)\n",
    "# fam_preds = torch.nn.functional.softmax(fam_preds,dim=1)\n",
    "\n",
    "# Get top k clans and their values\n",
    "def top5_argmaxes_with_values(input_tensor, mapping,k):\n",
    "    # Use torch.topk to find the top 5 values and their indices along dimension 1\n",
    "    top5_values, top5_indices = torch.topk(input_tensor, k, dim=1)\n",
    "\n",
    "    # Convert the indices tensor to a list of lists\n",
    "    indices_list = top5_indices.tolist()\n",
    "\n",
    "    # Convert the values tensor to a list of lists\n",
    "    values_list = top5_values.tolist()\n",
    "\n",
    "    # Apply the mapping to each index and pair it with the corresponding value\n",
    "    mapped_list = [[(mapping[index], value) for index, value in zip(indices, values)] for indices, values in zip(indices_list, values_list)]\n",
    "\n",
    "    # Sort the tuples in each list by value in descending order\n",
    "    sorted_list = [sorted(sublist, key=lambda x: x[1], reverse=True) for sublist in mapped_list]\n",
    "\n",
    "    return sorted_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_list = top5_argmaxes_with_values(clan_preds, idx_to_clan,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_list[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path('../data_esm_decoder') / 'maps.pkl', 'wb') as f:\n",
    "        pickle.dump(maps,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps[\"clan_count\"] = len(maps[\"clan_idx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model_name = 'esm2_t33_650M_UR50D'\n",
    "model, alphabet = pretrained.load_model_and_alphabet(model_name)\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "last_layer = model.num_layers\n",
    "embed_dim = model.embed_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier = mu.LinearHead3(embed_dim, 2*embed_dim, 657).to(device)\n",
    "state_dict = torch.load(\"../data/results/linear_3_run4/epoch_0.pth\")\n",
    "classifier.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(Path('../data_esm_decoder') / 'maps.pkl', 'rb') as f:\n",
    "        maps = pickle.load(f)\n",
    "idx_to_clan = {v: k for k, v in maps[\"clan_idx\"].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_converter = alphabet.get_batch_converter()\n",
    "# Prepare data (first 2 sequences from ESMStructuralSplitDataset superfamily / 4)\n",
    "data = [\n",
    "    (\"test\", \"MTTSAYTRRTALMTVGMAAATALTGCASTLVPATTQTIEEGAASSSSSERTDFSGEAKIENYDTSAGTYEPATREHRAKNVPKPILPEEANKNSVAGLHANIAYLAAAYIYGFNSGDAECVGKSALSSEDKASLTRAIGRVSGSTWLADPTLIISLKEATPRQDGDTYTWPALLTLKIGPFRVKNRSVEEVPESERSHEFPMDIVARYKDERWVFDTLPNDSSSSPGAGGTSRI\")\n",
    "]\n",
    "batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "batch_lens = (batch_tokens != alphabet.padding_idx).sum(1)\n",
    "\n",
    "\n",
    "results = model(batch_tokens.to(device), repr_layers=[33], return_contacts=True)\n",
    "token_representations = results[\"representations\"][33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = token_representations[0,1:-1,:]\n",
    "preds = classifier(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clan_idxs = torch.argmax(preds, dim=1)\n",
    "clan_idxs_list = clan_idxs.cpu().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top5_argmaxes_with_values(input_tensor, mapping,k):\n",
    "    # Use torch.topk to find the top 5 values and their indices along dimension 1\n",
    "    top5_values, top5_indices = torch.topk(input_tensor, k, dim=1)\n",
    "\n",
    "    # Convert the indices tensor to a list of lists\n",
    "    indices_list = top5_indices.tolist()\n",
    "\n",
    "    # Convert the values tensor to a list of lists\n",
    "    values_list = top5_values.tolist()\n",
    "\n",
    "    # Apply the mapping to each index and pair it with the corresponding value\n",
    "    mapped_list = [[(mapping[index], value) for index, value in zip(indices, values)] for indices, values in zip(indices_list, values_list)]\n",
    "\n",
    "    # Sort the tuples in each list by value in descending order\n",
    "    sorted_list = [sorted(sublist, key=lambda x: x[1], reverse=True) for sublist in mapped_list]\n",
    "\n",
    "    return sorted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_list = top5_argmaxes_with_values(preds, idx_to_clan,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_list[67:218]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clan_names = [idx_to_clan[x] for x in clan_idxs_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clan_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_data[\"P14528.1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clan_vector = hu.generate_domain_position_list(hmm_data, \"G8QNJ9.1\", maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, clan_vector = hu.generate_domain_position_list(hmm_data, \"G8QNJ9.1\", maps)\n",
    "with open(Path('../data_esm_decoder') / 'maps.pkl', 'rb') as f:\n",
    "    maps = pickle.load(f)\n",
    "idx_to_clan = {v: k for k, v in maps[\"clan_idx\"].items()}\n",
    "clan_vector_idxs = torch.argmax(torch.tensor(clan_vector).T,dim=1)\n",
    "clan_vector_idxs_list = clan_vector_idxs.cpu().tolist()\n",
    "clan_vector_names = [idx_to_clan[x] for x in clan_vector_idxs_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clan_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clan_vector_names[813:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps[\"clan_idx\"][\"CL0001\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps[\"fam_clan\"][\"PF00008.30\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_string_in_list(s, lst):\n",
    "    return any(s in item for item in lst)\n",
    "is_string_in_list(\"PF19843\",list(maps[\"fam_clan\"].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.ones(19633)*3\n",
    "input_tensor[1] = 10\n",
    "\n",
    "# Create a target where the one is at position 1\n",
    "target = torch.zeros(19633).long()\n",
    "target[0] = 1\n",
    "\n",
    "# Compute the cross-entropy loss\n",
    "loss = torch.nn.functional.cross_entropy(input_tensor.unsqueeze(0), target.argmax().unsqueeze(0))\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(0,10,(100,657),dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " x_reshaped = x.transpose(0, 1).unsqueeze(0)\n",
    "\n",
    "# Apply 1D average pooling\n",
    "local_pooled_embed = torch.nn.functional.avg_pool1d(x_reshaped, kernel_size=21, stride=1, padding=10)\n",
    "\n",
    "#Remove the extra batch dimension and transpose the tensor back to shape (L, d)\n",
    "local_pooled_embed = local_pooled_embed.squeeze(0).transpose(0, 1)\n",
    "local_pooled_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled = torch.nn.functional.avg_pool1d(x,kernel_size=21,stride=1,padding=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_unsqueezed = x.T.unsqueeze(0)\n",
    "\n",
    "# Apply 1D average pooling with a kernel size of 21, stride of 1, and padding of 10\n",
    "pooled = torch.nn.functional.avg_pool1d(x_unsqueezed, kernel_size=21, stride=1, padding=10)\n",
    "\n",
    "local_pooled_embed = pooled.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_pooled_embed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_unsqueezed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_pooled_embed[:,:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled[:,:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bruh =torch.zeros((3,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bruh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "length_limit = 4096 # Covers 99.75% sequences\n",
    "model_name =  'esm2_t33_650M_UR50D' #'esm2_t36_3B_UR50D'\n",
    "num_shards = 50\n",
    "data_utils = mu.DataUtils('../data', num_shards, model_name, length_limit, device)\n",
    "\n",
    "classifier = mu.LinearHead3NormedFam(data_utils.embedding_dim,data_utils.clan_count,data_utils.fam_count,1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the data type of the model parameters\n",
    "for name, param in classifier.named_parameters():\n",
    "    print(name, param.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(0,10,(100,20000)).float()\n",
    "b = torch.randint(1000,2000,(100,20000)).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_diff = torch.nn.functional.mse_loss(a,b,reduction=\"none\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_diff.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sse = squared_diff.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_row_sse = row_sse.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_row_sse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_row_sse.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_row_sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sse_soft = torch.nn.functional.softmax(row_sse,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sse_soft.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "\n",
    "with open('../data/results/try_lstm_run1/predictions_esm2_t33_650M_UR50D/agg_results.pkl', 'rb') as f:\n",
    "        results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results[\"clan_wise\"][655])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming `d` is your dictionary\n",
    "d = results[\"clan_wise\"]\n",
    "\n",
    "# 1) Get a list of the keys\n",
    "xs = []\n",
    "\n",
    "# 2) Create a tensor of length = the largest key + 1\n",
    "\n",
    "ys = []\n",
    "\n",
    "# Populate the tensor with the average of the values for each key\n",
    "for key, values in d.items():\n",
    "    ys.append(sum(values) / len(values))\n",
    "    xs.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(20,8))\n",
    "\n",
    "ax.bar(xs,ys)\n",
    "ax.set_xlabel('Clan')\n",
    "ax.set_ylabel('Average accuracy')\n",
    "ax.set_title(f'Prediction Accuracy Over Each Clan')\n",
    "\n",
    "ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hmmscan_utils as hu\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " with open('../data_esm_decoder/maps.pkl', 'rb') as f:\n",
    "    maps = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_clan = {v: k for k, v in maps[\"clan_idx\"].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clan_dict = {i:0 for i in range(657)}\n",
    "fam_dict = {i:0 for i in range(19633)}\n",
    "\n",
    "for i in tqdm(range(1,51)):\n",
    "    scan_shard = f\"../data/split_{i}_train_ids_full.fasta_scan.txt\"\n",
    "    hmm_dict = hu.parse_hmmscan_results(scan_shard)\n",
    "    for seq in hmm_dict:\n",
    "        hits = hmm_dict[seq][\"hit_domains\"]\n",
    "        fams = list(set([x[3] for x in hits]))\n",
    "        clans = list(set([maps[\"fam_clan\"][x] for x in fams]))\n",
    "        for clan in clans:\n",
    "            clan_dict[maps[\"clan_idx\"][clan]] += 1\n",
    "        for fam in fams:\n",
    "            fam_dict[maps[\"fam_idx\"][fam]] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(list(fam_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " with open('../data/clan_train_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(clan_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " with open('../data/fam_train_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(fam_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [my_dict[x] if x not in [655, 656] else 0 for x in xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps[\"clan_idx\"][\"CL0694\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(results[\"clan_wise\"][629])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_clan[629]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(20,8))\n",
    "\n",
    "ax.scatter(samples,ys)\n",
    "ax.set_xlabel('number of samples')\n",
    "ax.set_ylabel('Average accuracy')\n",
    "ax.set_title(f'Prediction Accuracy Over Each Clan')\n",
    "ax.set_xlim(0,10000)\n",
    "ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix = np.corrcoef(samples, ys)\n",
    "\n",
    "# The correlation coefficient is at [0, 1] or [1, 0] in the matrix\n",
    "correlation = correlation_matrix[0, 1]\n",
    "\n",
    "print(\"Correlation:\", correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys[81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_clan[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 6))\n",
    "plt.scatter(samples, ys)\n",
    "plt.axhline(1/657)\n",
    "# Set the labels and title (optional)\n",
    "plt.xlabel('X values')\n",
    "plt.ylabel('Y values')\n",
    "plt.title('Scatter Plot')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open and read both files\n",
    "with open('../data/train_ids_unique.txt', 'r') as train_file, open('../data/test_ids_unique.txt', 'r') as test_file:\n",
    "    train_sequences = set(line.strip() for line in train_file)\n",
    "    test_sequences = set(line.strip() for line in test_file)\n",
    "\n",
    "# Find sequence names that are in both files\n",
    "common_sequences = train_sequences & test_sequences\n",
    "\n",
    "len(common_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "with open('../data/results/try_lstm_part2/predictions_esm2_t33_650M_UR50D/agg_results.pkl', 'rb') as f:\n",
    "    tmp = pickle.load(f)\n",
    "\n",
    "acc = tmp['adjusted_acc']\n",
    "print(min(acc), max(acc))\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "\n",
    "ax.hist(acc, range=(0,1), bins=20)\n",
    "ax.set_xlabel('Accuracy')\n",
    "ax.set_ylabel('Proportion of Scores')\n",
    "ax.set_title(f'Prediction Accuracy Over Test Sequences: Avg = {np.nanmean(acc)}')\n",
    "\n",
    "ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "with open('../bash_scripts/bad_acc.txt', 'r') as f:\n",
    "    bad_preds = f.readlines()\n",
    "\n",
    "bad_preds.pop(0)\n",
    "shard_wise = defaultdict(list)\n",
    "\n",
    "for line in bad_preds:\n",
    "    error_seq = line.split()\n",
    "    shard_wise[error_seq[0]].append(error_seq[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "misclassified = {}\n",
    "for i in range(657):\n",
    "    misclassified[i] = 0\n",
    "\n",
    "for key in shard_wise.keys():\n",
    "    with open(f'../data/results/try_lstm_run1/predictions_esm2_t33_650M_UR50D/{key}', 'rb') as g:\n",
    "        results = pickle.load(g)\n",
    "\n",
    "        for vals in shard_wise[key]:\n",
    "            true = np.unique(results[vals]['clan_true'])\n",
    "            pred = results[vals]['clan_idx'][:,0]\n",
    "\n",
    "            for entry in true:\n",
    "                if entry not in [655, 656]:\n",
    "                    idx = (results[vals]['clan_true'] == entry)\n",
    "                    errors = pred[~idx]\n",
    "                    if True:#((errors == 655) + (errors == 656)).mean() != 1: # If prediction is 656/657 for other clan, don't count it\n",
    "                        score = (results[vals]['clan_true'][idx] == pred[idx]).mean()\n",
    "                        if score < 0.4:\n",
    "                            misclassified[entry] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "keys = list(misclassified.keys())\n",
    "vals = [misclassified[k] for k in keys]\n",
    "\n",
    "f, ax = plt.subplots(figsize=(15,6))\n",
    "\n",
    "ax.bar(keys, vals)\n",
    "ax.set_xlabel('Clan')\n",
    "ax.set_ylabel('Number of clans')\n",
    "ax.set_title(f'Distribution of clans in misclassified sequences')\n",
    "\n",
    "ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(vals)\n",
    "print(maps['clan_idx'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "sys.path.insert(0, '../library/')\n",
    "\n",
    "import visualizations as vz\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shard = np.random.randint(1,51)\n",
    "# shard = 29\n",
    "with open(f'../data/results/try_lstm_part2/predictions_esm2_t33_650M_UR50D/shard_{shard}.pkl', 'rb') as g:\n",
    "        results = pickle.load(g)\n",
    "\n",
    "with open(f'../data/maps.pkl', 'rb') as g:\n",
    "        maps = pickle.load(g)\n",
    "clan_map = list(maps['clan_idx'].keys())\n",
    "\n",
    "keys = list(results.keys())\n",
    "seq = keys[np.random.randint(0,len(keys))]\n",
    "# seq = 'I7MLC3.1'\n",
    "\n",
    "print(f'Shard {shard}: Sequence {seq}')\n",
    "vz.viewSingleClan(shard, seq, results, clan_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.insert(0, '../py_scripts')\n",
    "import visualizations as vz\n",
    "import pickle\n",
    "\n",
    "with open(f'../data/maps.pkl', 'rb') as g:\n",
    "        maps = pickle.load(g)\n",
    "fam_map = list(maps['fam_idx'].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/results/simple_resume_no_L1/single_pred.pkl', 'rb') as g:\n",
    "        results = pickle.load(g)\n",
    "\n",
    "seq = results['label']\n",
    "shard = results['shard']\n",
    "\n",
    "print(f'Shard {shard}: Sequence {seq}')\n",
    "vz.viewSingleFam(shard, seq, results, fam_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hmmscan_utils as hu\n",
    "\n",
    "scan_dict = hu.parse_hmmscan_results('../data/split_34_test_ids_full.fasta_scan.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scan_dict['I0AHU5.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = torch.randn((4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[[1,3],[0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify the indices for dimension 0 and dimension 1\n",
    "indices_dim0 = torch.tensor([1, 3])\n",
    "indices_dim1 = torch.tensor([0, 2])\n",
    "\n",
    "# Use advanced indexing to get the desired elements\n",
    "result = test[indices_dim0.reshape(-1, 1), indices_dim1]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the indices for dimension 0 and dimension 1\n",
    "indices_dim0 = torch.tensor([1, 3])\n",
    "indices_dim1 = [0,2]\n",
    "\n",
    "# Use advanced indexing to get the desired elements\n",
    "test[indices_dim0[:,None], indices_dim1] = 10\n",
    "\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = torch.tensor([1,2,3,4,1,2,1,2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (test2 == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = torch.tensor([1,2,3,4,5,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = torch.where(test2==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "sys.path.insert(0, '../library')\n",
    "sys.path.insert(0, '../py_scripts')\n",
    "import hmmscan_utils as hu\n",
    "import classifiers as cf\n",
    "import ml_utils as mu\n",
    "import visualizations as vz\n",
    "import torch\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "print(\"imported\")\n",
    "with open(f'../data/maps.pkl', 'rb') as g:\n",
    "        maps = pickle.load(g)\n",
    "fam_map = list(maps['fam_idx'].keys())\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# print(device)\n",
    "\n",
    "length_limit = 4096 # Covers 99.75% sequences\n",
    "model_name =  'esm2_t33_650M_UR50D' #'esm2_t36_3B_UR50D'\n",
    "num_shards = 50 ###### Replace with appropriate number ###################################\n",
    "data_utils = mu.DataUtils('../data', num_shards, model_name, length_limit, 'test', device)\n",
    "print(\"ESM2 loaded\")\n",
    "classifier = cf.FamModelSimple(data_utils.embedding_dim, data_utils.maps, device).to(device)\n",
    "classifier_path = Path('../data/results/simple_resume_no_L1/epoch_4.pth')\n",
    "classifier.load_state_dict(torch.load(classifier_path))\n",
    "print(\"Classifier loaded\")\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.inference_mode():\n",
    "\n",
    "    shard = np.random.randint(1,51)\n",
    "    shard = 39\n",
    "\n",
    "    hmm_dict = data_utils.parse_shard(shard)\n",
    "    keys = list(hmm_dict.keys())\n",
    "    key_idx = np.random.randint(0,len(keys))\n",
    "    seq_id = keys[key_idx]\n",
    "    seq_id = 'Q4UFZ3.1'\n",
    "\n",
    "    dataset = data_utils.get_dataset(shard)\n",
    "    dataset = data_utils.filter_batches(dataset, [seq_id])\n",
    "    data_loader = data_utils.get_dataloader(dataset)\n",
    "\n",
    "    label, seq, token = next(iter(data_loader))\n",
    "    token = token.to(device)\n",
    "    embedding = data_utils.get_embedding(token)\n",
    "    fam_vector, clan_vector = hu.generate_domain_position_list2(hmm_dict, seq_id, data_utils.maps)\n",
    "                    \n",
    "    stop_index = min(len(seq[0]), data_utils.length_limit)\n",
    "    fam_vector = torch.tensor(fam_vector[:stop_index,:]).to(device) # clip the clan_vector to the truncated sequence length\n",
    "    clan_vector = torch.tensor(clan_vector[:stop_index,:]).to(device)\n",
    "\n",
    "    weighted_preds, _ = classifier(embedding[\"representations\"][data_utils.last_layer][0,1:stop_index+1,:], clan_vector)\n",
    "    clan_fam_matrix = maps['clan_family_matrix'].to(device)\n",
    "    clan_fam_weights = torch.matmul(clan_vector,clan_fam_matrix)\n",
    "\n",
    "    for i in range(clan_fam_weights.shape[0]): #shape is Lxf\n",
    "        indices = torch.nonzero(clan_fam_weights[i]).squeeze() #indices for the softmax\n",
    "        weighted_preds[i,indices] = torch.softmax(weighted_preds[i,indices],dim=0)\n",
    " \n",
    "    results = {}\n",
    "    results[seq_id] = {}\n",
    "    top_two_vals, top_two_indices = torch.topk(weighted_preds, k=2, dim=1)\n",
    "\n",
    "    \n",
    "    results[seq_id]['fam_vals'] = top_two_vals.cpu().numpy()\n",
    "    results[seq_id]['fam_idx'] = top_two_indices.cpu().numpy()\n",
    "    results[seq_id]['fam_true'] = torch.argmax(fam_vector, dim=1).cpu().numpy()\n",
    "    results[seq_id]['fam_true_vals'] = fam_vector.max(dim=1)[1].cpu().numpy()\n",
    "    results['label'] = seq_id\n",
    "    results['shard'] = shard\n",
    "    print(f'Shard {shard}: Sequence {seq_id}')\n",
    "    vz.viewSingleFam(shard, seq_id, results, list(maps['fam_idx'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_dict['A6GJW3.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(weighted_preds.shape,weighted_preds.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raw_preds.shape,raw_preds.sum(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clan_fam_matrix = maps['clan_family_matrix'].to(device)\n",
    "clan_fam_weights = torch.matmul(clan_vector,clan_fam_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each row, print the indices where there are 1s\n",
    "weighted_preds_clone = weighted_preds.clone()\n",
    "for i in range(clan_fam_weights.shape[0]): #shape is Lxf\n",
    "    indices = torch.nonzero(clan_fam_weights[i]).squeeze() #indices for the softmax\n",
    "    weighted_preds_clone[i,indices] = torch.softmax(weighted_preds[i,indices],dim=0)\n",
    "    # if i==88:\n",
    "        # print(f\"Row {i}: {indices.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_preds[1,2892]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clan_fam_weights.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_preds.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_preds = torch.softmax(weighted_preds,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_preds[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps['clan_idx'][maps['fam_clan'][maps['idx_fam'][2892]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz = top5_argmaxes_with_values(weighted_preds, maps['idx_fam'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_preds_sm = torch.softmax(raw_preds,dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "seq_id = \"P14528.1\"\n",
    "shard = 1\n",
    "results[seq_id] = {}\n",
    "\n",
    "top_two_vals, top_two_indices = torch.topk(weighted_preds_clone, k=2, dim=1)\n",
    "\n",
    "results[seq_id]['fam_vals'] = top_two_vals.cpu().numpy()\n",
    "results[seq_id]['fam_idx'] = top_two_indices.cpu().numpy()\n",
    "results[seq_id]['fam_true'] = torch.argmax(fam_vector, dim=1).cpu().numpy()\n",
    "results['label'] = seq_id\n",
    "results['shard'] = shard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,\"../py_scripts\")\n",
    "\n",
    "import visualizations as vz\n",
    "print(f'Shard {shard}: Sequence {seq_id}')\n",
    "vz.viewSingleFam(shard, seq_id, results, list(maps['fam_idx'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "seq_id = \"P14528.1\"\n",
    "shard = 1\n",
    "results[seq_id] = {}\n",
    "\n",
    "top_two_vals, top_two_indices = torch.topk(raw_preds_sm, k=2, dim=1)\n",
    "\n",
    "results[seq_id]['fam_vals'] = top_two_vals.cpu().numpy()\n",
    "results[seq_id]['fam_idx'] = top_two_indices.cpu().numpy()\n",
    "results[seq_id]['fam_true'] = torch.argmax(fam_vector, dim=1).cpu().numpy()\n",
    "results['label'] = seq_id\n",
    "results['shard'] = shard\n",
    "print(f'Shard {shard}: Sequence {seq_id}')\n",
    "vz.viewSingleFam(shard, seq_id, results, list(maps['fam_idx'].keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-TreeHMM]",
   "language": "python",
   "name": "conda-env-.conda-TreeHMM-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
