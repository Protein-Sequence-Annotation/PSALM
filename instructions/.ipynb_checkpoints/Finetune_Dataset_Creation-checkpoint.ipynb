{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Bio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to incorporate negative examples (shuffled SwissProt sequences that we sample from) and small positive examples (only the domain region) for a finetuning dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Negative and Positive examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "# Load domain_train.fasta\n",
    "with open(\"../data/train_fasta/domain_train.fasta\", \"r\") as domain_file:\n",
    "    domain_records = list(SeqIO.parse(domain_file, \"fasta\"))\n",
    "\n",
    "# Load shuffle_train.fasta\n",
    "with open(\"../data/train_fasta/shuffle_train.fasta\", \"r\") as shuffle_file:\n",
    "    shuffle_records = list(SeqIO.parse(shuffle_file, \"fasta\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge and Shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(100)\n",
    "# Assuming domain_records and shuffle_records are your lists\n",
    "merged_records = domain_records + shuffle_records\n",
    "\n",
    "# Shuffle the merged list\n",
    "random.shuffle(merged_records)\n",
    "# ENSURE UNIQUE IDS/LABELS\n",
    "for i,seq in enumerate(merged_records):\n",
    "    seq.description = seq.description.split()[0]+f\" {i}\"\n",
    "    seq.seq = seq.seq.upper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shard and Write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir(\"../data/train_fasta_finetune\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/train_fasta_finetune/train_ids_full.fasta\",\"w\") as f:       \n",
    "    SeqIO.write(merged_records,f,\"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../library')\n",
    "import hmmscan_utils as hu\n",
    "\n",
    "data_dir = \"../data/train_fasta_finetune\"\n",
    "fasta_file = \"train_ids_full.fasta\"\n",
    "num_jobs = 50\n",
    "\n",
    "hu.split_fasta_file(fasta_file, data_dir, num_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Examples with Real Domains + Shuffled sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "sys.path.insert(0, '../library')\n",
    "import hmmscan_utils as hu\n",
    "\n",
    "random.seed(100)\n",
    "# Load maps\n",
    "with open(\"../data/maps.pkl\", \"rb\") as f:\n",
    "    maps = pickle.load(f)\n",
    "\n",
    "# Directory containing the fasta files\n",
    "dir_path = \"../data/train_fasta\"\n",
    "out_path = \"../data/train_fasta_finetune\"\n",
    "\n",
    "# Iterate over each fasta file in the directory\n",
    "for fasta_file in tqdm(glob.glob(os.path.join(dir_path, 'split_*_train_ids_full.fasta'))):\n",
    "    # Get the corresponding scan\n",
    "    file_suffix = fasta_file.split(\"/\")[-1] \n",
    "    hmmscan_dict = hu.parse_hmmscan_results(f\"../data/train_scan/{file_suffix}_scan.txt\")\n",
    "\n",
    "    # Use BioPython to load the fasta file\n",
    "    sequences = list(SeqIO.parse(fasta_file, \"fasta\"))\n",
    "\n",
    "    for seq in sequences:\n",
    "        # print(seq.id)\n",
    "        # Get clan_vector\n",
    "        try:\n",
    "            _, clan_vector = hu.generate_domain_position_list(hmmscan_dict, seq.id, maps)\n",
    "        except:\n",
    "            # print(f\"Error with {seq.id}\")\n",
    "            continue\n",
    "        # find the indices where the clan vector is 656\n",
    "        indices = [i for i, x in enumerate(clan_vector) if x == 656]\n",
    "\n",
    "        # If there are no clan 656 domains, skip\n",
    "        if len(indices) == 0:\n",
    "            continue\n",
    "\n",
    "        # Shuffle seq.seq only where clan 656 is present\n",
    "        sequence = list(seq.seq)\n",
    "        values = [sequence[i] for i in indices]\n",
    "        random.shuffle(values)\n",
    "        for i, index in enumerate(indices):\n",
    "            sequence[index] = values[i]\n",
    "        seq.seq = Seq(\"\".join(sequence))\n",
    "    \n",
    "    # Write the shuffled sequences to a new fasta file\n",
    "    with open(f\"{out_path}/{file_suffix}\", \"w\") as f:\n",
    "        SeqIO.write(sequences, f, \"fasta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:protein_annotation_dl-protllm]",
   "language": "python",
   "name": "conda-env-protein_annotation_dl-protllm-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
